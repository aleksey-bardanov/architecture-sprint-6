# Описание будущей архитектуры системы предоставляет агрегационных услуг в сфере страхования, компании InsureTech

## Проблемы текущего решения

- В B2C сегменте бизнеса компания столкнулась с неудовлетворенностью пользователей. Сайт загружает страницы по несколько минут. Пиковая нагрузка 50 RPS на запросы поиска и 10 RPS на запросы оформления.
- В B2B сегменте поступают жалобы на нарушение SLA. Один из партнёров нагружает API до 250 RPS вместо оговоренных 20 RPS.
- Команда медленно реагирует на падение приложения, т.к. медленно узнаёт о падении сервиса. 500 т.р. стоит час простоя ++ репутационные потери. 

## Требования бизнеса

- Бесперебойная работа и доступность сервиса 24/7 во всех часовых поясах регионов России. 
- RTO — 45 мин 
- RPO — 15 мин
- доступность 99.9% 
- Объем хранимых данных - 50 Гб (ФИО, контакты, документы клиентов, история заявок, информация о продуктах и услугах)

## Предложение по технологической архитектуре приложения

Схемы:
- [текущая архитектура](InureTech_технологическая%20архитектура_as-is.drawio)
- [целевая архитектура](./InureTech_технологическая%20архитектура_to-be.drawio)

### Стратегия масштабирования и отказоустойчивости

Для обеспечения требований бизнеса (доступность сервиса 99.9%) наиболее подходящим решением является Active-Active стратегия обеспечения отказоустойчивости. При этом поддерживается несколько экземпляров приложения на разных серверах и при отказе одного из них балансировщик нагрузки должен перераспределить запросы между оставшимися. Это решение обеспечит возможность масштабирования и георезервирования системы. Каждый экземпляр приложения должен работать в собственном кластере Kubernetes, чтобы снизить зависимость от сетевой связанности между разными ЦОД и от фейловер механизмов Kubernetes. При этом БД также придется поддерживать на нескольких ЦОД и обеспечивать бэкап. 

Таким образом целевая архитектура будет включать:
- несколько активных экземпляров приложения, развернутых в ЦОД в различных часовых поясах в разных кластерах Kubernetes
- GSLB, позволяющий перенаправить трафик к ближайшему к пользователю экземпляру приложения
- кластер Patroni для БД, обеспечивающий доступность БД при отказе одного из ЦОД 

### Шардирование базы данных

Так как система будет обслуживать пользователей в различных регионах и часовых поясах, то имеется возможность для разделения базы данных по географическому признаку и держать в ЦОД только данные клиентов, находящихся в этом же регионе. Предполагается, что в нормальном режиме работы в региональный ЦОД будут поступать в основном запросы клиентов из того же региона, поэтому нет смысла производить поиск данных среди клиентов из других регионов. Такое разделение должно повысить производительность приложения, за счет уменьшения размеров региональных БД и повышения скорости обработки запросов к ним. При необходимости получения данных из других регионов, запрос будет переадресован через прокси-сервер.

Для обеспечения отказоустойчивости потребуется бэкап сервис БД.